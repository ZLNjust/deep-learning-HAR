{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR CNN training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, labels,  = read_data(data_path=\"./data/\", split=\"train\") # train\n",
    "X_train,X_test, labels_train, labels_test = train_test_split(X, labels, test_size = 0.2, random_state = 0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 491     # Batch size\n",
    "seq_len = 3000         # Number of steps\n",
    "learning_rate = 0.001\n",
    "epochs = 1000\n",
    "\n",
    "n_classes = 6\n",
    "n_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len,1], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Convolutional Layers\n",
    "\n",
    "Note: Should we use a different activation? Like tf.nn.tanh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 3000, 1) --> (batch, 750, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=4, strides=4, padding='same')\n",
    "    \n",
    "    # (batch, 750, 18) --> (batch, 150, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=5, strides=5, padding='same')\n",
    "    \n",
    "    # (batch, 150, 36) --> (batch, 30, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=72, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=5, strides=5, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, flatten and pass to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_3, (-1, 30*72))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/1000 Iteration: 5 Train loss: 0.933012 Train acc: 0.757638\n",
      "Epoch: 9/1000 Iteration: 10 Train loss: 0.911482 Train acc: 0.763747\n",
      "Epoch: 9/1000 Iteration: 10 Validation loss:    nan Validation acc: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zl-mac/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/zl-mac/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/1000 Iteration: 15 Train loss: 0.818641 Train acc: 0.767821\n",
      "Epoch: 19/1000 Iteration: 20 Train loss: 0.780838 Train acc: 0.773931\n",
      "Epoch: 19/1000 Iteration: 20 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 24/1000 Iteration: 25 Train loss: 0.729767 Train acc: 0.771894\n",
      "Epoch: 29/1000 Iteration: 30 Train loss: 0.702380 Train acc: 0.767821\n",
      "Epoch: 29/1000 Iteration: 30 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 34/1000 Iteration: 35 Train loss: 0.672469 Train acc: 0.778004\n",
      "Epoch: 39/1000 Iteration: 40 Train loss: 0.673438 Train acc: 0.790224\n",
      "Epoch: 39/1000 Iteration: 40 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 44/1000 Iteration: 45 Train loss: 0.647145 Train acc: 0.784114\n",
      "Epoch: 49/1000 Iteration: 50 Train loss: 0.635431 Train acc: 0.782077\n",
      "Epoch: 49/1000 Iteration: 50 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 54/1000 Iteration: 55 Train loss: 0.627004 Train acc: 0.788187\n",
      "Epoch: 59/1000 Iteration: 60 Train loss: 0.586239 Train acc: 0.794297\n",
      "Epoch: 59/1000 Iteration: 60 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 64/1000 Iteration: 65 Train loss: 0.572359 Train acc: 0.782077\n",
      "Epoch: 69/1000 Iteration: 70 Train loss: 0.550772 Train acc: 0.796334\n",
      "Epoch: 69/1000 Iteration: 70 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 74/1000 Iteration: 75 Train loss: 0.535978 Train acc: 0.814664\n",
      "Epoch: 79/1000 Iteration: 80 Train loss: 0.529588 Train acc: 0.802444\n",
      "Epoch: 79/1000 Iteration: 80 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 84/1000 Iteration: 85 Train loss: 0.519668 Train acc: 0.818737\n",
      "Epoch: 89/1000 Iteration: 90 Train loss: 0.505795 Train acc: 0.816701\n",
      "Epoch: 89/1000 Iteration: 90 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 94/1000 Iteration: 95 Train loss: 0.502280 Train acc: 0.816701\n",
      "Epoch: 99/1000 Iteration: 100 Train loss: 0.487544 Train acc: 0.812627\n",
      "Epoch: 99/1000 Iteration: 100 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 104/1000 Iteration: 105 Train loss: 0.482320 Train acc: 0.820774\n",
      "Epoch: 109/1000 Iteration: 110 Train loss: 0.479169 Train acc: 0.818737\n",
      "Epoch: 109/1000 Iteration: 110 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 114/1000 Iteration: 115 Train loss: 0.482098 Train acc: 0.822811\n",
      "Epoch: 119/1000 Iteration: 120 Train loss: 0.475041 Train acc: 0.818737\n",
      "Epoch: 119/1000 Iteration: 120 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 124/1000 Iteration: 125 Train loss: 0.458804 Train acc: 0.830957\n",
      "Epoch: 129/1000 Iteration: 130 Train loss: 0.459150 Train acc: 0.832994\n",
      "Epoch: 129/1000 Iteration: 130 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 134/1000 Iteration: 135 Train loss: 0.441423 Train acc: 0.830957\n",
      "Epoch: 139/1000 Iteration: 140 Train loss: 0.434371 Train acc: 0.839104\n",
      "Epoch: 139/1000 Iteration: 140 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 144/1000 Iteration: 145 Train loss: 0.449540 Train acc: 0.832994\n",
      "Epoch: 149/1000 Iteration: 150 Train loss: 0.422958 Train acc: 0.847251\n",
      "Epoch: 149/1000 Iteration: 150 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 154/1000 Iteration: 155 Train loss: 0.431251 Train acc: 0.845214\n",
      "Epoch: 159/1000 Iteration: 160 Train loss: 0.427356 Train acc: 0.830957\n",
      "Epoch: 159/1000 Iteration: 160 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 164/1000 Iteration: 165 Train loss: 0.413924 Train acc: 0.837067\n",
      "Epoch: 169/1000 Iteration: 170 Train loss: 0.438422 Train acc: 0.822811\n",
      "Epoch: 169/1000 Iteration: 170 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 174/1000 Iteration: 175 Train loss: 0.426760 Train acc: 0.837067\n",
      "Epoch: 179/1000 Iteration: 180 Train loss: 0.443161 Train acc: 0.843177\n",
      "Epoch: 179/1000 Iteration: 180 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 184/1000 Iteration: 185 Train loss: 0.413840 Train acc: 0.843177\n",
      "Epoch: 189/1000 Iteration: 190 Train loss: 0.402597 Train acc: 0.851324\n",
      "Epoch: 189/1000 Iteration: 190 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 194/1000 Iteration: 195 Train loss: 0.402697 Train acc: 0.830957\n",
      "Epoch: 199/1000 Iteration: 200 Train loss: 0.404578 Train acc: 0.843177\n",
      "Epoch: 199/1000 Iteration: 200 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 204/1000 Iteration: 205 Train loss: 0.391190 Train acc: 0.869654\n",
      "Epoch: 209/1000 Iteration: 210 Train loss: 0.396243 Train acc: 0.861507\n",
      "Epoch: 209/1000 Iteration: 210 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 214/1000 Iteration: 215 Train loss: 0.384064 Train acc: 0.857434\n",
      "Epoch: 219/1000 Iteration: 220 Train loss: 0.413230 Train acc: 0.843177\n",
      "Epoch: 219/1000 Iteration: 220 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 224/1000 Iteration: 225 Train loss: 0.395735 Train acc: 0.849287\n",
      "Epoch: 229/1000 Iteration: 230 Train loss: 0.392750 Train acc: 0.843177\n",
      "Epoch: 229/1000 Iteration: 230 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 234/1000 Iteration: 235 Train loss: 0.369366 Train acc: 0.859470\n",
      "Epoch: 239/1000 Iteration: 240 Train loss: 0.395837 Train acc: 0.849287\n",
      "Epoch: 239/1000 Iteration: 240 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 244/1000 Iteration: 245 Train loss: 0.386140 Train acc: 0.841141\n",
      "Epoch: 249/1000 Iteration: 250 Train loss: 0.374883 Train acc: 0.859470\n",
      "Epoch: 249/1000 Iteration: 250 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 254/1000 Iteration: 255 Train loss: 0.374114 Train acc: 0.849287\n",
      "Epoch: 259/1000 Iteration: 260 Train loss: 0.384731 Train acc: 0.847251\n",
      "Epoch: 259/1000 Iteration: 260 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 264/1000 Iteration: 265 Train loss: 0.377270 Train acc: 0.853360\n",
      "Epoch: 269/1000 Iteration: 270 Train loss: 0.370764 Train acc: 0.855397\n",
      "Epoch: 269/1000 Iteration: 270 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 274/1000 Iteration: 275 Train loss: 0.379026 Train acc: 0.857434\n",
      "Epoch: 279/1000 Iteration: 280 Train loss: 0.355218 Train acc: 0.851324\n",
      "Epoch: 279/1000 Iteration: 280 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 284/1000 Iteration: 285 Train loss: 0.357231 Train acc: 0.855397\n",
      "Epoch: 289/1000 Iteration: 290 Train loss: 0.375597 Train acc: 0.849287\n",
      "Epoch: 289/1000 Iteration: 290 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 294/1000 Iteration: 295 Train loss: 0.381600 Train acc: 0.835031\n",
      "Epoch: 299/1000 Iteration: 300 Train loss: 0.390785 Train acc: 0.851324\n",
      "Epoch: 299/1000 Iteration: 300 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 304/1000 Iteration: 305 Train loss: 0.386325 Train acc: 0.847251\n",
      "Epoch: 309/1000 Iteration: 310 Train loss: 0.351404 Train acc: 0.865580\n",
      "Epoch: 309/1000 Iteration: 310 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 314/1000 Iteration: 315 Train loss: 0.350410 Train acc: 0.853360\n",
      "Epoch: 319/1000 Iteration: 320 Train loss: 0.352795 Train acc: 0.851324\n",
      "Epoch: 319/1000 Iteration: 320 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 324/1000 Iteration: 325 Train loss: 0.352476 Train acc: 0.857434\n",
      "Epoch: 329/1000 Iteration: 330 Train loss: 0.356172 Train acc: 0.861507\n",
      "Epoch: 329/1000 Iteration: 330 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 334/1000 Iteration: 335 Train loss: 0.377284 Train acc: 0.835031\n",
      "Epoch: 339/1000 Iteration: 340 Train loss: 0.334865 Train acc: 0.867617\n",
      "Epoch: 339/1000 Iteration: 340 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 344/1000 Iteration: 345 Train loss: 0.356503 Train acc: 0.855397\n",
      "Epoch: 349/1000 Iteration: 350 Train loss: 0.347432 Train acc: 0.867617\n",
      "Epoch: 349/1000 Iteration: 350 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 354/1000 Iteration: 355 Train loss: 0.362721 Train acc: 0.857434\n",
      "Epoch: 359/1000 Iteration: 360 Train loss: 0.359789 Train acc: 0.857434\n",
      "Epoch: 359/1000 Iteration: 360 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 364/1000 Iteration: 365 Train loss: 0.347672 Train acc: 0.861507\n",
      "Epoch: 369/1000 Iteration: 370 Train loss: 0.344568 Train acc: 0.869654\n",
      "Epoch: 369/1000 Iteration: 370 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 374/1000 Iteration: 375 Train loss: 0.345622 Train acc: 0.871690\n",
      "Epoch: 379/1000 Iteration: 380 Train loss: 0.332868 Train acc: 0.861507\n",
      "Epoch: 379/1000 Iteration: 380 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 384/1000 Iteration: 385 Train loss: 0.356147 Train acc: 0.871690\n",
      "Epoch: 389/1000 Iteration: 390 Train loss: 0.333712 Train acc: 0.875764\n",
      "Epoch: 389/1000 Iteration: 390 Validation loss:    nan Validation acc: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 394/1000 Iteration: 395 Train loss: 0.322839 Train acc: 0.879837\n",
      "Epoch: 399/1000 Iteration: 400 Train loss: 0.327428 Train acc: 0.849287\n",
      "Epoch: 399/1000 Iteration: 400 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 404/1000 Iteration: 405 Train loss: 0.329591 Train acc: 0.865580\n",
      "Epoch: 409/1000 Iteration: 410 Train loss: 0.325936 Train acc: 0.865580\n",
      "Epoch: 409/1000 Iteration: 410 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 414/1000 Iteration: 415 Train loss: 0.335705 Train acc: 0.853360\n",
      "Epoch: 419/1000 Iteration: 420 Train loss: 0.322496 Train acc: 0.879837\n",
      "Epoch: 419/1000 Iteration: 420 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 424/1000 Iteration: 425 Train loss: 0.346715 Train acc: 0.867617\n",
      "Epoch: 429/1000 Iteration: 430 Train loss: 0.334746 Train acc: 0.865580\n",
      "Epoch: 429/1000 Iteration: 430 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 434/1000 Iteration: 435 Train loss: 0.333496 Train acc: 0.867617\n",
      "Epoch: 439/1000 Iteration: 440 Train loss: 0.330802 Train acc: 0.863544\n",
      "Epoch: 439/1000 Iteration: 440 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 444/1000 Iteration: 445 Train loss: 0.301808 Train acc: 0.879837\n",
      "Epoch: 449/1000 Iteration: 450 Train loss: 0.321851 Train acc: 0.890020\n",
      "Epoch: 449/1000 Iteration: 450 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 454/1000 Iteration: 455 Train loss: 0.318178 Train acc: 0.879837\n",
      "Epoch: 459/1000 Iteration: 460 Train loss: 0.320995 Train acc: 0.859470\n",
      "Epoch: 459/1000 Iteration: 460 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 464/1000 Iteration: 465 Train loss: 0.330626 Train acc: 0.853360\n",
      "Epoch: 469/1000 Iteration: 470 Train loss: 0.338011 Train acc: 0.859470\n",
      "Epoch: 469/1000 Iteration: 470 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 474/1000 Iteration: 475 Train loss: 0.316542 Train acc: 0.877800\n",
      "Epoch: 479/1000 Iteration: 480 Train loss: 0.330003 Train acc: 0.869654\n",
      "Epoch: 479/1000 Iteration: 480 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 484/1000 Iteration: 485 Train loss: 0.324638 Train acc: 0.873727\n",
      "Epoch: 489/1000 Iteration: 490 Train loss: 0.306429 Train acc: 0.881874\n",
      "Epoch: 489/1000 Iteration: 490 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 494/1000 Iteration: 495 Train loss: 0.328302 Train acc: 0.867617\n",
      "Epoch: 499/1000 Iteration: 500 Train loss: 0.324322 Train acc: 0.867617\n",
      "Epoch: 499/1000 Iteration: 500 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 504/1000 Iteration: 505 Train loss: 0.310374 Train acc: 0.869654\n",
      "Epoch: 509/1000 Iteration: 510 Train loss: 0.321751 Train acc: 0.885947\n",
      "Epoch: 509/1000 Iteration: 510 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 514/1000 Iteration: 515 Train loss: 0.289300 Train acc: 0.883910\n",
      "Epoch: 519/1000 Iteration: 520 Train loss: 0.315552 Train acc: 0.875764\n",
      "Epoch: 519/1000 Iteration: 520 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 524/1000 Iteration: 525 Train loss: 0.306032 Train acc: 0.865580\n",
      "Epoch: 529/1000 Iteration: 530 Train loss: 0.318373 Train acc: 0.879837\n",
      "Epoch: 529/1000 Iteration: 530 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 534/1000 Iteration: 535 Train loss: 0.294600 Train acc: 0.885947\n",
      "Epoch: 539/1000 Iteration: 540 Train loss: 0.323353 Train acc: 0.869654\n",
      "Epoch: 539/1000 Iteration: 540 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 544/1000 Iteration: 545 Train loss: 0.308391 Train acc: 0.881874\n",
      "Epoch: 549/1000 Iteration: 550 Train loss: 0.294730 Train acc: 0.883910\n",
      "Epoch: 549/1000 Iteration: 550 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 554/1000 Iteration: 555 Train loss: 0.322046 Train acc: 0.877800\n",
      "Epoch: 559/1000 Iteration: 560 Train loss: 0.303902 Train acc: 0.881874\n",
      "Epoch: 559/1000 Iteration: 560 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 564/1000 Iteration: 565 Train loss: 0.312429 Train acc: 0.867617\n",
      "Epoch: 569/1000 Iteration: 570 Train loss: 0.309908 Train acc: 0.875764\n",
      "Epoch: 569/1000 Iteration: 570 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 574/1000 Iteration: 575 Train loss: 0.312859 Train acc: 0.885947\n",
      "Epoch: 579/1000 Iteration: 580 Train loss: 0.320220 Train acc: 0.873727\n",
      "Epoch: 579/1000 Iteration: 580 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 584/1000 Iteration: 585 Train loss: 0.313514 Train acc: 0.869654\n",
      "Epoch: 589/1000 Iteration: 590 Train loss: 0.291977 Train acc: 0.887984\n",
      "Epoch: 589/1000 Iteration: 590 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 594/1000 Iteration: 595 Train loss: 0.298810 Train acc: 0.879837\n",
      "Epoch: 599/1000 Iteration: 600 Train loss: 0.302684 Train acc: 0.879837\n",
      "Epoch: 599/1000 Iteration: 600 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 604/1000 Iteration: 605 Train loss: 0.321910 Train acc: 0.875764\n",
      "Epoch: 609/1000 Iteration: 610 Train loss: 0.301799 Train acc: 0.877800\n",
      "Epoch: 609/1000 Iteration: 610 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 614/1000 Iteration: 615 Train loss: 0.304953 Train acc: 0.871690\n",
      "Epoch: 619/1000 Iteration: 620 Train loss: 0.291287 Train acc: 0.879837\n",
      "Epoch: 619/1000 Iteration: 620 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 624/1000 Iteration: 625 Train loss: 0.303549 Train acc: 0.881874\n",
      "Epoch: 629/1000 Iteration: 630 Train loss: 0.305015 Train acc: 0.867617\n",
      "Epoch: 629/1000 Iteration: 630 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 634/1000 Iteration: 635 Train loss: 0.308406 Train acc: 0.879837\n",
      "Epoch: 639/1000 Iteration: 640 Train loss: 0.302676 Train acc: 0.861507\n",
      "Epoch: 639/1000 Iteration: 640 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 644/1000 Iteration: 645 Train loss: 0.301688 Train acc: 0.877800\n",
      "Epoch: 649/1000 Iteration: 650 Train loss: 0.301365 Train acc: 0.875764\n",
      "Epoch: 649/1000 Iteration: 650 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 654/1000 Iteration: 655 Train loss: 0.301592 Train acc: 0.875764\n",
      "Epoch: 659/1000 Iteration: 660 Train loss: 0.311937 Train acc: 0.879837\n",
      "Epoch: 659/1000 Iteration: 660 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 664/1000 Iteration: 665 Train loss: 0.289224 Train acc: 0.877800\n",
      "Epoch: 669/1000 Iteration: 670 Train loss: 0.292747 Train acc: 0.879837\n",
      "Epoch: 669/1000 Iteration: 670 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 674/1000 Iteration: 675 Train loss: 0.277860 Train acc: 0.890020\n",
      "Epoch: 679/1000 Iteration: 680 Train loss: 0.294398 Train acc: 0.883910\n",
      "Epoch: 679/1000 Iteration: 680 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 684/1000 Iteration: 685 Train loss: 0.276447 Train acc: 0.898167\n",
      "Epoch: 689/1000 Iteration: 690 Train loss: 0.297017 Train acc: 0.871690\n",
      "Epoch: 689/1000 Iteration: 690 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 694/1000 Iteration: 695 Train loss: 0.291032 Train acc: 0.875764\n",
      "Epoch: 699/1000 Iteration: 700 Train loss: 0.276509 Train acc: 0.887984\n",
      "Epoch: 699/1000 Iteration: 700 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 704/1000 Iteration: 705 Train loss: 0.293029 Train acc: 0.877800\n",
      "Epoch: 709/1000 Iteration: 710 Train loss: 0.292244 Train acc: 0.881874\n",
      "Epoch: 709/1000 Iteration: 710 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 714/1000 Iteration: 715 Train loss: 0.280018 Train acc: 0.894094\n",
      "Epoch: 719/1000 Iteration: 720 Train loss: 0.277306 Train acc: 0.890020\n",
      "Epoch: 719/1000 Iteration: 720 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 724/1000 Iteration: 725 Train loss: 0.284857 Train acc: 0.877800\n",
      "Epoch: 729/1000 Iteration: 730 Train loss: 0.306978 Train acc: 0.869654\n",
      "Epoch: 729/1000 Iteration: 730 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 734/1000 Iteration: 735 Train loss: 0.288720 Train acc: 0.887984\n",
      "Epoch: 739/1000 Iteration: 740 Train loss: 0.280530 Train acc: 0.894094\n",
      "Epoch: 739/1000 Iteration: 740 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 744/1000 Iteration: 745 Train loss: 0.283869 Train acc: 0.900204\n",
      "Epoch: 749/1000 Iteration: 750 Train loss: 0.291421 Train acc: 0.875764\n",
      "Epoch: 749/1000 Iteration: 750 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 754/1000 Iteration: 755 Train loss: 0.278951 Train acc: 0.885947\n",
      "Epoch: 759/1000 Iteration: 760 Train loss: 0.273014 Train acc: 0.883910\n",
      "Epoch: 759/1000 Iteration: 760 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 764/1000 Iteration: 765 Train loss: 0.265847 Train acc: 0.894094\n",
      "Epoch: 769/1000 Iteration: 770 Train loss: 0.289593 Train acc: 0.879837\n",
      "Epoch: 769/1000 Iteration: 770 Validation loss:    nan Validation acc: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 774/1000 Iteration: 775 Train loss: 0.280531 Train acc: 0.881874\n",
      "Epoch: 779/1000 Iteration: 780 Train loss: 0.269988 Train acc: 0.896130\n",
      "Epoch: 779/1000 Iteration: 780 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 784/1000 Iteration: 785 Train loss: 0.283124 Train acc: 0.883910\n",
      "Epoch: 789/1000 Iteration: 790 Train loss: 0.286814 Train acc: 0.881874\n",
      "Epoch: 789/1000 Iteration: 790 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 794/1000 Iteration: 795 Train loss: 0.270526 Train acc: 0.892057\n",
      "Epoch: 799/1000 Iteration: 800 Train loss: 0.273597 Train acc: 0.896130\n",
      "Epoch: 799/1000 Iteration: 800 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 804/1000 Iteration: 805 Train loss: 0.285030 Train acc: 0.877800\n",
      "Epoch: 809/1000 Iteration: 810 Train loss: 0.282367 Train acc: 0.887984\n",
      "Epoch: 809/1000 Iteration: 810 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 814/1000 Iteration: 815 Train loss: 0.288433 Train acc: 0.881874\n",
      "Epoch: 819/1000 Iteration: 820 Train loss: 0.270656 Train acc: 0.898167\n",
      "Epoch: 819/1000 Iteration: 820 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 824/1000 Iteration: 825 Train loss: 0.281943 Train acc: 0.887984\n",
      "Epoch: 829/1000 Iteration: 830 Train loss: 0.263126 Train acc: 0.906314\n",
      "Epoch: 829/1000 Iteration: 830 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 834/1000 Iteration: 835 Train loss: 0.272960 Train acc: 0.885947\n",
      "Epoch: 839/1000 Iteration: 840 Train loss: 0.256756 Train acc: 0.900204\n",
      "Epoch: 839/1000 Iteration: 840 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 844/1000 Iteration: 845 Train loss: 0.252845 Train acc: 0.898167\n",
      "Epoch: 849/1000 Iteration: 850 Train loss: 0.271661 Train acc: 0.885947\n",
      "Epoch: 849/1000 Iteration: 850 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 854/1000 Iteration: 855 Train loss: 0.277615 Train acc: 0.887984\n",
      "Epoch: 859/1000 Iteration: 860 Train loss: 0.279256 Train acc: 0.892057\n",
      "Epoch: 859/1000 Iteration: 860 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 864/1000 Iteration: 865 Train loss: 0.276105 Train acc: 0.881874\n",
      "Epoch: 869/1000 Iteration: 870 Train loss: 0.271432 Train acc: 0.881874\n",
      "Epoch: 869/1000 Iteration: 870 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 874/1000 Iteration: 875 Train loss: 0.272298 Train acc: 0.883910\n",
      "Epoch: 879/1000 Iteration: 880 Train loss: 0.282279 Train acc: 0.879837\n",
      "Epoch: 879/1000 Iteration: 880 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 884/1000 Iteration: 885 Train loss: 0.291102 Train acc: 0.883910\n",
      "Epoch: 889/1000 Iteration: 890 Train loss: 0.246614 Train acc: 0.898167\n",
      "Epoch: 889/1000 Iteration: 890 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 894/1000 Iteration: 895 Train loss: 0.253855 Train acc: 0.902240\n",
      "Epoch: 899/1000 Iteration: 900 Train loss: 0.260607 Train acc: 0.890020\n",
      "Epoch: 899/1000 Iteration: 900 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 904/1000 Iteration: 905 Train loss: 0.262257 Train acc: 0.890020\n",
      "Epoch: 909/1000 Iteration: 910 Train loss: 0.264081 Train acc: 0.890020\n",
      "Epoch: 909/1000 Iteration: 910 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 914/1000 Iteration: 915 Train loss: 0.259568 Train acc: 0.894094\n",
      "Epoch: 919/1000 Iteration: 920 Train loss: 0.265736 Train acc: 0.890020\n",
      "Epoch: 919/1000 Iteration: 920 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 924/1000 Iteration: 925 Train loss: 0.257414 Train acc: 0.902240\n",
      "Epoch: 929/1000 Iteration: 930 Train loss: 0.261211 Train acc: 0.900204\n",
      "Epoch: 929/1000 Iteration: 930 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 934/1000 Iteration: 935 Train loss: 0.282946 Train acc: 0.883910\n",
      "Epoch: 939/1000 Iteration: 940 Train loss: 0.269470 Train acc: 0.885947\n",
      "Epoch: 939/1000 Iteration: 940 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 944/1000 Iteration: 945 Train loss: 0.269435 Train acc: 0.881874\n",
      "Epoch: 949/1000 Iteration: 950 Train loss: 0.247284 Train acc: 0.896130\n",
      "Epoch: 949/1000 Iteration: 950 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 954/1000 Iteration: 955 Train loss: 0.261894 Train acc: 0.885947\n",
      "Epoch: 959/1000 Iteration: 960 Train loss: 0.279369 Train acc: 0.879837\n",
      "Epoch: 959/1000 Iteration: 960 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 964/1000 Iteration: 965 Train loss: 0.254813 Train acc: 0.902240\n",
      "Epoch: 969/1000 Iteration: 970 Train loss: 0.255559 Train acc: 0.908350\n",
      "Epoch: 969/1000 Iteration: 970 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 974/1000 Iteration: 975 Train loss: 0.276005 Train acc: 0.885947\n",
      "Epoch: 979/1000 Iteration: 980 Train loss: 0.243234 Train acc: 0.898167\n",
      "Epoch: 979/1000 Iteration: 980 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 984/1000 Iteration: 985 Train loss: 0.252212 Train acc: 0.904277\n",
      "Epoch: 989/1000 Iteration: 990 Train loss: 0.253191 Train acc: 0.898167\n",
      "Epoch: 989/1000 Iteration: 990 Validation loss:    nan Validation acc: nan\n",
      "Epoch: 994/1000 Iteration: 995 Train loss: 0.248551 Train acc: 0.900204\n",
      "Epoch: 999/1000 Iteration: 1000 Train loss: 0.264379 Train acc: 0.890020\n",
      "Epoch: 999/1000 Iteration: 1000 Validation loss:    nan Validation acc: nan\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIAIoQAAiBAKAIDI/wd2DdB5evSYRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121f6ddd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121f6dba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints-cnn/har.ckpt\n",
      "Test accuracy: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zl-mac/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/zl-mac/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 0}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
